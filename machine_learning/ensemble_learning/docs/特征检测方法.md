# 第三章 基于多维分析的样本静态特征检测方案

## 3.1 特征检测方案概述
本章针对PE文件的多维结构与行为模式，提出了一种系统化的静态特征检测框架。该框架包括基于字节分布的直方图特征、基于局部熵分布的熵直方图特征、基于PE数据结构的静态特征、基于规则与正则的字符串匹配特征，以及基于Opcode片段的函数行为特征。所有特征均通过并行化流水线自动提取，并以浮点向量形式输出，以供后续分类模型使用。系统整体流程如图3.1所示：首先从原始二进制中并行提取多源特征，然后对字符型与类别型信息进行特征哈希与归一化，最终输出统一的高维特征向量，用于后续的集成学习中。

## 3.2 PE数据结构特征解析
在PE格式中，DOS头、PE文件头、数据目录、节表（Section Table）、导入/导出表、资源表、重定位表等数据结构蕴含了丰富的元信息。本节将逐项说明如何从这些结构中提取特征，并分析其风险指示意义。

### 3.2.1 PE软件结构概述
PE（Portable Executable）格式是Windows可执行文件的二进制封装标准，其总体布局可分为：DOS Header、PE Header、Optional Header、Section Table、Data Directories。PE Header中包含文件类型（Machine）、入口点地址、节区对齐方式等信息，Optional Header中包含子系统类型、数据目录偏移等。我们针对其中的关键字段（如TimeDateStamp、Subsystem、SizeOfImage、起始入口点入口节名等）进行数值化统计，以捕捉编译器版本、打包方式、时间戳异动等特征。

### 3.2.2 各结构特征检测
(1) DOS头及PE文件头  
从DOS Header中的Magic、e_lfanew、UsedBytesInLastPage等字段提取数值特征，结合PE Header中的Signature、Machine、NumberOfSections等，用于识别非标准编译器或异常捆绑器。  
(2) 节表及节区数据  
对每个节区（section）读取其Name、VirtualSize、RawDataSize、Entropy、Characteristics等属性。通过统计可读（MEM_READ）、可写（MEM_WRITE）、可执行（MEM_EXECUTE）节区的数量与平均大小，以及资源节区（.rsrc）数量，来反映壳保护与代码混淆强度。  
(3) 关键数据结构  
导入表（Import Table）与导出表（Export Table）分别统计函数数量、DLL名称、函数名哈希分布等；资源表（Resource Table）中资源类型、大小与嵌入脚本；重定位表（Relocation Table）中条目个数与分布差异，用于检测自修改代码或动态加载行为。  
(4) 其他重要数据  
调试信息（Debug Directory）字段可包含PDB路径，反映开发环境；TLS（Thread Local Storage）回调函数指针可指示恶意持久化；WIN_CERTIFICATE数字签名结构可用于判断签名状态及证书异常。

以下六类静态特征经统一向量化合并后构成967维PE静态特征：
- ByteHistogram：256维全局字节分布特征
- ByteEntropyHistogram：256维局部熵值变化特征
- GeneralFileInfo：10维文件基本信息（如文件大小、TLS回调数、重定位数等）
- HeaderFileInfo：62维PE头字段信息
- ExportsInfo：128维导出表结构特征
- SectionInfo：255维节区属性向量化特征（大小、熵、属性哈希等）
总计维度：256+256+10+62+128+255=967。

### 3.2.3 特征哈希转换
（
解释本文是如何通过特征哈希将上述字符串特征转化为可用于后续模型训练的
特征向量的）
对于字符串与类别型数据（如节区名称、导出函数名、DLL名、Section 特性列表等），我们采用Scikit-Learn的FeatureHasher进行哈希编码。记输入键值对集合 $\{(k_i,v_i)\}$，哈希后生成固定维度 $D$ 的向量 $\mathbf{h}\in\mathbb{R}^D$：
\[
h_j = \sum_{i:\,\mathrm{hash}(k_i)\bmod D=j} \mathrm{sign}(k_i)\cdot v_i,\quad j=0,\dots,D-1,
\]
其中 $\mathrm{sign}(k)$ 基于二次哈希决定正负号，以减轻冲突影响。通过该方式，可将任意新出现的键映射至相同维度，不依赖词典，同时保证在线与离线一致性。

## 3.3 直方图特征模型检测
### 3.3.1 字节直方图
本节提取256维全局字节分布特征，并与256维熵直方图并行使用，形成512维直方图输入至CNN模块。具体过程如下：
- 统计每个字节（0–255）在文件中的出现次数，构成256维原始计数向量；
- 对计数向量进行归一化处理，得到256维概率分布特征；
- 与256维熵直方图拼接，最终形成512维输入特征。

### 3.3.2 字节熵直方图
本节构造256维局部熵直方图特征，与全局字节直方图并行使用，共计512维输入。主要步骤如下：
- 采用2 KB窗口、1 KB步长滑动视图计算窗口熵，以减少内存复制开销；
- 将字节值右移4位映射至16个bin，将熵值量化为16级，共生成16×16=256个格点特征；
- 对熵直方图进行归一化处理，输出256维向量。

## 3.4 字符规则匹配特征
### 3.4.1 规则匹配方法概述
采用正则表达式对二进制原始流进行无状态匹配，提取路径、注册表（使用简化"reg"匹配）、URL、IP、MZ/PE标识、加壳与挖矿相关关键字等。所有模式均预编译，以 $O(n)$ 复杂度扫描样本。

### 3.4.2 Yara规则匹配
引入三类Yara规则：已知壳签名规则（packer.yar）、密码学常量匹配规则（crypto_signatures.yar）、基于训练集黑样本生成的自定义规则（rule20.yar）。通过Yara API并行匹配后，统计触发规则数与匹配比率，形成2维特征 $\{\text{packer\_count},\,\text{yargen\_count}\}$。

### 3.4.3 自定义规则匹配
用户可扩展Yara规则集，匹配反调试API名称、防火墙模块字符串、虚拟化检测特征、加壳器特征等模式，并将其计数纳入后续模型。规则的编写应遵循Yara语法规范，并配合白名单文件过滤低质量匹配。

### 3.4.4 特征工程综合概览
为了支持后续轻量级特征工程模型，本模块共采集56维综合特征，覆盖以下五大类：
- 节区信息（16维）：包括OEP节名长度、可读/写/执行节区大小与熵值占比、资源节区数量等；
- 字符串模式匹配（26维）：针对13种模式（比特币/莱特币/门罗币钱包、文件路径、注册表、URL、IP、MZ/PE标识、矿池、CPU、GPU、coin等），统计出现次数与平均匹配长度；
- YARA规则检测（2维）：统计packer.yar与自定义rule20.yar规则的触发次数；
- 关键字计数（5维）：统计常见杀毒软件进程名、调试器名、矿池域名、密码学算法名、数字货币名出现频次；
- 操作码分析（7维）：基于函数边界与Capstone反汇编的函数数量、Opcode总数、唯一Opcode种类、均值、方差等统计量。

## 3.5 操作码（Opcode）特征分析和检测
通过字节模式 `\x55\x8b\xec[^\xc3]*\xc3` 提取x86函数边界，并使用Capstone离线反汇编获取指令助记符，映射至Opcode索引字典。统计全样本函数片段的函数个数、Opcode总数、平均数、方差、唯一种类数等7维特征，用于反映代码复杂度与逆向难度。

## 3.6 大模型特征分析和检测

（大模型能够从哪些地方去分析和判断一个PE软件是否为恶意PE？是通过逆向
后的PE代码、PE元数据、还是什么别的？该怎么用大模型去检测和提取PE中
的固定特征用于后续的模型训练？）

本工作同时探索预训练Transformer模型（如BERT）在PE元数据与逆向字符串上的应用，将二进制视为文本序列，提取深层上下文特征。实验表明，大模型在未知壳与模糊编码样本中提供了额外分类增益，但考虑到推理资源消耗，目前仅作为后续可选方案。

