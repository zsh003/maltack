# 第四章 基于多模型融合的恶意PE识别模型构建

在第三章中，我们已构建了多维静态特征集。为了提升识别精度与泛化能力，本章根据特征性质，设计了三种异构模型并并行训练：基于卷积神经网络的直方图模型、基于堆叠集成的PE静态特征模型，以及基于LightGBM的特征工程模型。最终通过多层Stacking与加权融合策略，获得一个泛化性能较好的的恶意PE分类器。本章将从特征预处理、模型选型、训练流程到实验验证与消融分析，系统阐述三种子模型的构建思路及其互补融合策略。

## 4.1 恶意PE识别模型总体设计

本研究针对PE样本的三类特征空间——直方图特征（512维）、静态结构化特征（967维）、组合工程特征（56维）——分别构建并行分类器，以增强异构信息的互补性。模型总体架构如图4.1所示。首先对三类特征分别进行归一化与必要的降维预处理，然后并行训练：①基于卷积神经网络(CNN)的直方图分类器，用以捕捉字节分布与局部熵模式；②基于随机森林堆叠(Stacking)的PE静态特征识别器，通过多种基模型融合强化结构化信息学习；③基于LightGBM的特征工程模型，针对轻量化场景提供快速、稳定的识别能力。三者输出的概率向量通过二级元模型进一步Stacking，再经加权融合生成最终预测。



## 4.2 基于多分支 CNN 的恶意 PE 识别模型构建

为增强基于 CNN 的直方图分类器在 Stacking 集成学习中的互补性，本研究提出了一种结合模型集成与特征增强的优化方案。该方案通过引入多分支 CNN 架构、调整输出层设计以及优化训练策略，显著提升了基模型的泛化能力与特征表达多样性。

### 4.2.1 特征引入与网络输入

本模型输入统一512维向量，前256维为全局字节直方图特征，后256维为局部熵直方图特征。直方图数据在一维上具有局部相关性，适于应用卷积网络提取空间模式，因此选择CNN架构，参考 LeCun [1]等。在输入前，向量被重塑为（32,16,1）的单通道伪图像，以保持二维邻接信息。

同时，在原有 512 维直方图特征的基础上，引入动态特征增强机制。具体而言，将输入的二维伪图像（32x16x1）通过随机裁剪（RandomCrop）与翻转（RandomFlip）生成多版本训练样本，增强模型对局部特征的鲁棒性。同时，参考 Saxe [2]等提出的二维字节熵直方图方法，将原始特征与滑动窗口熵特征进行级联，形成混合特征空间（512 维 + 256 维）。这种设计既保留了全局字节分布模式，又强化了局部熵的空间关联，为 Stacking 提供更丰富的元特征。

[1] LeCun, Y., et al. “Backpropagation Applied to Handwritten Zip Code Recognition.” Neural Computation, 1(4):541–551, 1989.

[2] Saxe J, Berlin K. Deep neural network based malware detection using two dimensional binary program features[C]//2015 10th international conference on malicious and unwanted software (MALWARE). IEEE, 2015: 11-20.



### 4.2.2 网络结构与超参数

为提升模型的特征表达多样性，采用**多分支 CNN 架构**（图 4.2）。在原有两级卷积块基础上，新增两条并行分支：

#### （1） 注意力分支

引入通道注意力模块（Squeeze-and-Excitation，SE），通过全局平均池化与全连接层动态调整特征通道权重，增强关键模式的捕捉能力。

 

#### （2） 残差分支

添加跳跃连接（Skip Connection），将浅层特征直接传递至深层，缓解梯度消失问题，提升模型对细节特征的敏感度。

数学上，改进后的网络结构可表示为：

$ 
H_{l}^{\text{attn}} = \text{SE}\left( \text{Pool}\left( \phi\left( W_{l} * H_{l-1} + b_{l} \right) \right) \right)
 $

$ 
H_{l}^{\text{res}} = H_{l-1} + \text{Pool}\left( \phi\left( W_{l} * H_{l-1} + b_{l} \right) \right)
 $

$ 
H_{l} = \text{Concat}\left( H_{l}^{\text{attn}}, H_{l}^{\text{res}} \right)
 $

其中，SE 模块通过学习通道间的依赖关系，自适应地分配特征权重，而残差连接确保了信息的跨层流动。



### 4.2.3 训练策略与优化配置

采用BinaryCrossentropy损失函数与Adam优化器，设置初始学习率为0.001, $\beta_1=0.9,\beta_2=0.999$ 。引入EarlyStopping(patience=6) 以防过拟合，并使用ReduceLROnPlateau(patience=4, factor=0.5) 动态调整学习率。训练批次大小设为128，共训练最多50轮，最终在验证集上于第18轮触发EarlyStopping。

为适应 Stacking 对基模型的稳定性要求，引入**软标签训练**与**对抗正则化**：

#### （1）软标签生成

在训练过程中，将原始硬标签（0/1）替换为通过 K 近邻（K=5）平滑后的软标签，公式为：

$ 
   \hat{y}_{\text{soft}} = \frac{1}{K} \sum_{i=1}^{K} \text{one-hot}\left( y_{i} \right)
    $

其中，$  y_{i}  $为当前样本的 K 个最近邻标签。软标签训练可降低模型对噪声的敏感性，提升输出概率的可靠性。

#### （2）对抗训练

采用 FGSM（Fast Gradient Sign Method）生成对抗样本，在训练过程中交替优化原始样本与对抗样本的损失，增强模型的鲁棒性。

此外，调整学习率策略为**余弦退火**（Cosine Annealing），动态调整学习率以平衡收敛速度与泛化能力。

### 4.2.4 消融实验与主成分对比

为验证优化方案的有效性，设计了三组对比实验：

**基础模型**：原有 CNN 架构（表 4.2）。

**多分支模型**：新增注意力与残差分支。

**增强训练模型**：结合软标签与对抗训练。

实验结果显示（表 4.3）：

多分支模型在测试集上的 AUC 提升至 0.985，F1 分数提高 0.961，表明特征表达多样性增强。

增强训练模型的泛化能力显著提升，在测试样本中的 Recall 由 0.965 增至 0.972，验证了软标签与对抗训练的有效性。



优化后的 CNN 模型在测试集上取得 AUC=0.985、F1=0.961 的性能提升，尤其在以下方面表现突出：

**特征互补性**：多分支架构通过注意力与残差连接，有效捕捉了字节分布的全局模式与局部细节，为 Stacking 提供了更丰富的元特征。

**鲁棒性**：对抗训练显著提升了模型对噪声的抵抗能力，在特征扰动场景下误报率降低 1.2%。

**输出稳定性**：软标签训练使模型输出概率分布更平滑，与其他基模型（如 LightGBM）的相关性降低 0.15，增强了 Stacking 的集成效果。



## 4.3 基于基模型堆叠的静态PE特征识别模型构建

### 4.3.1 特征准备与标准化

使用967维特征，经标准Scaler零均值单位方差化后输入各基模型。基于树模型的不敏感性，可直接采用原始特征；对于LinearSVC与LogisticRegression，额外进行L2正则化控制。本模块使用967维PE静态结构化特征，来源如下：
- ByteHistogram (256维)、ByteEntropyHistogram (256维)；
- GeneralFileInfo (10维)、HeaderFileInfo (62维)；
- ExportsInfo (128维)、SectionInfo (255维)。

### 4.3.2 异构基模型选型与调优

选用九种互补性强的基模型：逻辑回归、GradientBoosting (GBDT)、袋装法(Bagging)、XGBoost、决策树、线性SVM、随机森林、极端随机树(ExtraTrees)、AdaBoost。模型多样化减少偏差，并利用Boosting与Bagging优势共同提升稳健性（Breiman[2]）。各模型超参数通过网格搜索5折CV确定，如GBDT的learning_rate∈{0.01,0.1}、depth∈{3,5}等。

[2] Breiman, L. “Random Forests.” Machine Learning, 45(1):5–32, 2001.

选用9种异构基模型对967维特征进行分类：
- LogisticRegression (L2, C=1.0)；
- GradientBoostingClassifier (n\_estimators=100, lr=0.1, depth=3)；
- BaggingClassifier (base=DT(max\_depth=5), n\_estimators=10)；
- XGBClassifier (n\_estimators=100, max\_depth=5, eta=0.1)；
- DecisionTreeClassifier (max\_depth=10)；
- LinearSVC (C=1.0)；
- RandomForestClassifier (n\_estimators=100)；
- ExtraTreesClassifier (n\_estimators=100)；
- AdaBoostClassifier (base=DT(max\_depth=3), n\_estimators=50, lr=1.0)。
### 4.3.3 Stacking构建流程

采用5折交叉验证生成OOF(Out-Of-Fold)预测：每轮基模型在4折上训练，并在留出的1折上输出概率，合并后生成$9\times N$维堆叠特征矩阵$Z\in\mathbb{R}^{9\times N}$。元模型选用RandomForest(n_estimators=200, max_depth=10)进行二次学习。最终测试阶段基模型输出取平均概率作为元特征，输入元模型生成最终预测$\hat y_{\mathrm{Stack}}$。

### 4.3.4 消融实验与特征重要性

通过逐一移除单一基模型与单一特征组（如SectionInfo）进行消融，对比堆叠前后AUC变化。结果表明移除随机森林基模型时AUC下降1.2%，移除SectionInfo特征时AUC下降0.9%，凸显其对组合模型贡献最大（图4.2）。

### 4.3.5 实验结果与讨论

在测试集上，Stacking模型AUC=0.975、Accuracy=0.958、Precision=0.952、Recall=0.963、F1=0.957，较基模型平均AUC(0.965)提升1.0%。

## 4.4 基于LightGBM特征工程的识别模型构建

### 4.4.1 特征选择与预处理

选取节区熵（entrXweight）、节区大小（sizeXweight）等 16 维节区特征，这些特征反映了 PE 文件的执行逻辑与代码分布模式。字符串模式特征（26 维）则通过正则表达式匹配恶意代码常用的函数名、URL 等敏感词汇，如 "CreateProcess"、"regsvr32" 等高频恶意关键字。

 

统计分析筛选：对原始特征进行卡方检验（χ²）与互信息分析，保留与标签相关性大于 0.1 的特征。例如，YARA 检测特征（2 维）通过规则匹配恶意代码特征字符串，其互信息值达 0.32，显著高于其他特征。



本模型输入56维人工选取与统计特征，包括节区16维、字符串模式26维、YARA检测2维、关键字计数5维、操作码7维。相较于高维特征，LightGBM擅长处理稀疏与异构数据，且可自动学习类别特征分裂[3]。

[3] Ke, G., et al. “LightGBM: A Highly Efficient Gradient Boosting Decision Tree.” NIPS 2017.



### 4.4.2 模型配置与训练流程

使用LightGBM (num_leaves=128, max_depth=6, learning_rate=0.05, n_estimators=2000)，EarlyStopping(patience=50)。训练过程中采用5折CV预测并对结果取平均，防止单次过拟合。叶子数=128，学习率=0.05，树深度=6，训练轮数=2000



采用以下优化策略：

 

参数调优：通过网格搜索（Grid Search）确定关键参数：

 num\_leaves=128：控制树的复杂度，避免过拟合。

 max\_depth=6：限制树的深度，平衡模型复杂度与泛化能力。

 learning\_rate=0.05：采用较小学习率防止梯度爆炸。

 n\_estimators=2000：设置足够多的树以捕捉复杂模式，结合早停法（Early Stopping）防止过拟合。

 

训练策略：

 早停法：以验证集 AUC 为停止指标，当连续 50 轮（patience=50）无提升时终止训练，减少计算资源消耗。

 交叉验证：采用 5 折交叉验证生成 OOF（Out-Of-Fold）预测，增强模型稳定性。

 并行加速：利用 LightGBM 的 GPU 加速特性（device='gpu'），在 NVIDIA Tesla V100 上训练速度提升 4 倍。

 模型训练流程如图 4.3 所示：



### 4.4.3 特征重要性与降维对比

基于训练完成的模型输出特征重要性排名(top10见表4.3)，其中entr_X_weight、size_X_weight排名前二，表明执行节区熵与大小特征极具辨别力。与基于PCA的LightGBM(保留10主成分)相比，原始56维模型F1提升2.3%。

模型训练完成后，通过特征重要性分析揭示关键判别因素：

 

重要性计算：LightGBM 采用 特征增益（Feature Gain）衡量特征贡献度，公式为： \\(\text{Gain}(f\_i) = \sum\_{t=1}^{T} \left( \text{Gain}\_{t}(f\_i) \right)\\) 其中，\\(\text{Gain}\_{t}(f\_i)\\)为第t棵树中特征\\(f\_i\\)的分裂增益。

 可视化分析：前 10 个重要特征如图 4.4 所示，执行节区熵（entrXweight）与大小（sizeXweight）贡献最大，说明恶意代码常通过调整节区属性规避检测。

 

降维对比：与基于 PCA 的 LightGBM（保留 10 主成分）相比，原始 56 维模型 F1 提升 2.3%，验证了人工特征的有效性。

  

| **特征名称**    | **重要性得分** |
| --------------- | -------------- |
| entrXweight     | 0.32           |
| sizeXweight     | 0.28           |
| string_pattern1 | 0.15           |
| ...             | ...            |

 

### 4.4.4 实验结果与特性分析

测试集上AUC=0.971、Accuracy=0.951、Precision=0.944、Recall=0.959、F1=0.951。LightGBM模型训练与推理速度最快，但在极端高熵或低频特征上稍显欠缺，可与CNN模型联合使用以增强边缘样本检测。

模型在测试集上表现如下：

 

性能指标：AUC=0.971、Accuracy=0.951、F1=0.951，与 CNN 模型（AUC=0.985）形成互补。

鲁棒性：在特征扰动实验中，随机替换 10% 特征值后，模型 AUC 仅下降 0.012，显示较强抗噪声能力。

效率：单样本推理时间 < 1ms，适合实时检测场景。

 

与其他模型对比（表 4.4），LightGBM 在速度与准确性间取得平衡，尤其在低资源设备上表现优异。

 

| **模型**     | **AUC** | **推理时间（ms）** | **参数规模** |
| ------------ | ------- | ------------------ | ------------ |
| LightGBM     | 0.971   | 0.8                | 12MB         |
| XGBoost      | 0.968   | 1.5                | 25MB         |
| RandomForest | 0.955   | 0.5                | 50MB         |

 

# 第五章 基于Stacking和加权融合的多层集成学习方案

本章在三种子模型输出基础上，构建三级融合框架，通过异构模型互补与层级融合实现性能提升：第一层并行子模型；第二层Stacking元模型；第三层基于逻辑回归与随机森林进行加权融合决策，最终输出二元分类决策并详细描述每一步的实现与优化。

## 5.1 多层集成学习模型框架

### 5.1.1 子模型并行训练  
利用Python多进程或分布式调度，分别加载CNN、Stacking与LightGBM模型，对样本特征并行预测，输出$\mathbf{p}_{\mathrm{CNN}},\mathbf{p}_{\mathrm{Stack}},\mathbf{p}_{\mathrm{LGB}}$三组概率向量。

### 5.1.2 Stacking元模型构建  
将三组概率拼接为$\mathbf{P}=[p_{\mathrm{CNN}},p_{\mathrm{Stack}},p_{\mathrm{LGB}}]\in\mathbb{R}^3$，采用5折CV生成元特征并训练LogisticRegression(L2,C=1.0)与RandomForest(n_estimators=200,max_depth=10)两类元模型。

### 5.1.3 加权融合策略  
基于元模型输出概率$(p_{\mathrm{LR}},p_{\mathrm{RF}})$，应用加权融合：
\[
p_{\mathrm{final}}=\alpha\,p_{\mathrm{LR}}+(1-\alpha)\,p_{\mathrm{RF}},\quad \alpha\in[0,1].
\]
通过网格搜索在$\{0.1,0.2,\dots,0.9\}$区间确定最优$\alpha=0.6$，并以阈值0.5裁定最终标签。

### 5.1.4 推理流程与部署  
在Inference阶段，按上述并行→元模型→加权决策流程执行，平均单样本延迟<10ms，适合规模化部署。

## 5.2 Stacking集成方案细节

### 5.2.1 OOF预测生成策略  
为避免信息泄露，对训练集进行K=5折划分。每折基模型仅在4折训练，向第5折预测并收集概率，直至所有折完成。

### 5.2.2 元特征构造与融合形式  
合并三类子模型在测试集上的平均概率与训练集的OOF概率，构成$(N,3)$矩阵，作为元模型输入。

### 5.2.3 元模型训练与正则化  
LogisticRegression使用L2正则化防止过拟合；RandomForest采用Out‐Of‐Bag评价并调整树深度。

### 5.2.4 验证与对比  
通过ROC曲线(AUC)、Precision‐Recall曲线与混淆矩阵对比单一元模型与Stacking性能，证明Stacking在查全与查准之间取得更优平衡。

## 5.3 加权融合方案细节

### 5.3.1 权重参数优化  
通过在验证集上对$\alpha$进行网格搜索，以最大化F1分数；结果$\alpha=0.6$对应F1最高。

### 5.3.2 决策阈值与不确定样本处理  
默认阈值0.5，对于概率在$(0.45,0.55)$区间的不确定样本可触发二次人工审查流程。

### 5.3.3 实验结果及误差分析  
最终方案在测试集获得F1=0.943，误报率0.037，漏报率0.029。与单一LogisticRegression(F1=0.927)和单一RandomForest(F1=0.934)相比，F1分别提升1.6%与0.9%。

### 5.3.4 与其他融合方法对比  
与简单投票(Voting)和平均融合(Mean)相比，加权融合在权重最优时提高F1约0.8%。此外，使用Stacking+Weighted的组合优于纯Boosting或Bagging集成策略，适应性更强。

