# 第四章 基于多模型融合的恶意PE识别模型构建

在第三章中，我们已构建了多维静态特征集。为了提升识别精度与泛化能力，本章根据特征性质，设计了三种异构模型并并行训练：基于卷积神经网络的直方图模型、基于堆叠集成的PE静态特征模型，以及基于LightGBM的特征工程模型。最终通过多层Stacking与加权融合策略，获得一个泛化性能较好的的恶意PE分类器。本章将从特征预处理、模型选型、训练流程到实验验证与消融分析，系统阐述三种子模型的构建思路及其互补融合策略。

## 4.1 恶意PE识别模型总体设计

本研究针对PE样本的三类特征空间——直方图特征（512维）、静态结构化特征（967维）、组合工程特征（56维）——分别构建并行分类器，以增强异构信息的互补性。模型总体架构如图4.1所示。首先对三类特征分别进行归一化与必要的降维预处理，然后并行训练：①基于卷积神经网络(CNN)的直方图分类器，用以捕捉字节分布与局部熵模式；②基于随机森林堆叠(Stacking)的PE静态特征识别器，通过多种基模型融合强化结构化信息学习；③基于LightGBM的特征工程模型，针对轻量化场景提供快速、稳定的识别能力。三者输出的概率向量通过二级元模型进一步Stacking，再经加权融合生成最终预测。

### 4.1.1 特征预处理与降维

为消除量纲差异，所有输入特征均先进行Min-Max归一化。对于967维静态特征，额外采用基于方差保留率90%的主成分分析(PCA)作为基线对照组，以评估集合模型在高维空间的稳健性。PCA实验表明，前200个主成分保留了95%以上的信息量，但Stacking模型在原始967维上性能更佳（见表4.1），故最终未在主流程中降维。

## 4.2 基于CNN的恶意PE识别模型构建

### 4.2.1 特征引入与网络输入

本模型输入统一512维向量，前256维为全局字节直方图特征，后256维为局部熵直方图特征。直方图数据在一维上具有局部相关性，适于应用卷积网络提取空间模式，因此选择CNN架构（参考 LeCun 等[1]）。在输入前，向量被重塑为$(32,16,1)$的单通道伪图像，以保持二维邻接信息。

### 4.2.2 网络结构与超参数

模型结构如下：
1. ConvBlock1：60个$2\times2$卷积核，步长1，ReLU激活，后接$2\times2$最大池化；
2. ConvBlock2：200个$2\times2$卷积核，步长1，ReLU激活，后接$2\times2$最大池化；
3. Flatten：将特征图展平为向量；
4. Dense1：500节点，全连接，ReLU激活 + Dropout(0.2)；
5. Output：1节点，全连接，Sigmoid激活输出$\hat y_{\mathrm{CNN}}$。

网络可公式化为：
\[
H_1 = \mathrm{Pool}(\phi(W_1 * X + b_1)),\quad
H_2 = \mathrm{Pool}(\phi(W_2 * H_1 + b_2)),\quad
\hat y = \sigma(W_3 H_2 + b_3),
\]
其中$\phi(\cdot)$为ReLU，$\sigma(\cdot)$为Sigmoid。

### 4.2.3 训练策略与优化配置

采用BinaryCrossentropy损失函数与Adam优化器(初始学习率0.001, $\beta_1=0.9$, $\beta_2=0.999$)。引入EarlyStopping(patience=6)以防过拟合，并使用ReduceLROnPlateau(patience=4, factor=0.5)动态调整学习率。训练批次大小设为128，共训练最多50轮，最终在验证集上于第18轮触发EarlyStopping。

### 4.2.4 消融实验与主成分对比

为验证卷积层设计的重要性，设计了两组消融实验：①移除第二卷积层，仅保留单层Conv+Pool；②将512维输入直接送入两层Dense(500,250)结构。结果显示，两组消融模型的F1分别下降5.2%与7.8%，表明卷积结构对局部模式捕捉至关重要。与前文PCA基线相比，本CNN模型在同等参数量下性能提升3.1%（表4.2）。

### 4.2.5 实验结果与特性分析

最终在测试集上取得AUC=0.982、Accuracy=0.957、Precision=0.949、Recall=0.965、F1=0.956。CNN模型尤其擅长检测高熵段加壳样本，但在类零日样本中Recall略有下降，提示未来可结合大模型补偿边缘样本识别。

## 4.3 基于基模型堆叠的静态PE特征识别模型构建

### 4.3.1 特征准备与标准化

使用967维特征，经标准Scaler零均值单位方差化后输入各基模型。基于树模型的不敏感性，可直接采用原始特征；对于LinearSVC与LogisticRegression，额外进行L2正则化控制。本模块使用967维PE静态结构化特征，来源如下：
- ByteHistogram (256维)、ByteEntropyHistogram (256维)；
- GeneralFileInfo (10维)、HeaderFileInfo (62维)；
- ExportsInfo (128维)、SectionInfo (255维)。

### 4.3.2 异构基模型选型与调优

选用九种互补性强的基模型：逻辑回归、GradientBoosting (GBDT)、袋装法(Bagging)、XGBoost、决策树、线性SVM、随机森林、极端随机树(ExtraTrees)、AdaBoost。模型多样化减少偏差，并利用Boosting与Bagging优势共同提升稳健性（Breiman[2]）。各模型超参数通过网格搜索5折CV确定，如GBDT的learning_rate∈{0.01,0.1}、depth∈{3,5}等。

选用9种异构基模型对967维特征进行分类：
- LogisticRegression (L2, C=1.0)；
- GradientBoostingClassifier (n\_estimators=100, lr=0.1, depth=3)；
- BaggingClassifier (base=DT(max\_depth=5), n\_estimators=10)；
- XGBClassifier (n\_estimators=100, max\_depth=5, eta=0.1)；
- DecisionTreeClassifier (max\_depth=10)；
- LinearSVC (C=1.0)；
- RandomForestClassifier (n\_estimators=100)；
- ExtraTreesClassifier (n\_estimators=100)；
- AdaBoostClassifier (base=DT(max\_depth=3), n\_estimators=50, lr=1.0)。
- 
### 4.3.3 Stacking构建流程

采用5折交叉验证生成OOF(Out-Of-Fold)预测：每轮基模型在4折上训练，并在留出的1折上输出概率，合并后生成$9\times N$维堆叠特征矩阵$Z\in\mathbb{R}^{N\times 9}$。元模型选用RandomForest(n_estimators=200, max_depth=10)进行二次学习。最终测试阶段基模型输出取平均概率作为元特征，输入元模型生成最终预测$\hat y_{\mathrm{Stack}}$。

### 4.3.4 消融实验与特征重要性

通过逐一移除单一基模型与单一特征组（如SectionInfo）进行消融，对比堆叠前后AUC变化。结果表明移除随机森林基模型时AUC下降1.2%，移除SectionInfo特征时AUC下降0.9%，凸显其对组合模型贡献最大（图4.2）。

### 4.3.5 实验结果与讨论

在测试集上，Stacking模型AUC=0.975、Accuracy=0.958、Precision=0.952、Recall=0.963、F1=0.957，较基模型平均AUC(0.965)提升1.0%。该方法对低维噪声鲁棒，但在样本不平衡场景下Precision略有下降，后续可结合Cost-Sensitive Learning。

## 4.4 基于LightGBM特征工程的识别模型构建

### 4.4.1 特征选择与预处理

本模型输入56维人工选取与统计特征，包括节区16维、字符串模式26维、YARA检测2维、关键字计数5维、操作码7维。相较于高维特征，LightGBM擅长处理稀疏与异构数据，且可自动学习类别特征分裂[3]。

### 4.4.2 模型配置与训练流程

使用LightGBM (num_leaves=128, max_depth=6, learning_rate=0.05, n_estimators=2000)，EarlyStopping(patience=50)。训练过程中采用5折CV预测并对结果取平均，防止单次过拟合。叶子数=128，学习率=0.05，树深度=6，训练轮数=2000

### 4.4.3 特征重要性与降维对比

基于训练完成的模型输出特征重要性排名(top10见表4.3)，其中entr_X_weight、size_X_weight排名前二，表明执行节区熵与大小特征极具辨别力。与基于PCA的LightGBM(保留10主成分)相比，原始56维模型F1提升2.3%。

### 4.4.4 实验结果与特性分析

测试集上AUC=0.971、Accuracy=0.951、Precision=0.944、Recall=0.959、F1=0.951。LightGBM模型训练与推理速度最快，但在极端高熵或低频特征上稍显欠缺，可与CNN模型联合使用以增强边缘样本检测。

# 第五章 基于Stacking和加权融合的多层集成学习方案

本章在三种子模型输出基础上，构建三级融合框架，通过异构模型互补与层级融合实现性能提升：第一层并行子模型；第二层Stacking元模型；第三层基于逻辑回归与随机森林进行加权融合决策，最终输出二元分类决策并详细描述每一步的实现与优化。

## 5.1 多层集成学习模型框架

### 5.1.1 子模型并行训练  
利用Python多进程或分布式调度，分别加载CNN、Stacking与LightGBM模型，对样本特征并行预测，输出$\mathbf{p}_{\mathrm{CNN}},\mathbf{p}_{\mathrm{Stack}},\mathbf{p}_{\mathrm{LGB}}$三组概率向量。

### 5.1.2 Stacking元模型构建  
将三组概率拼接为$\mathbf{P}=[p_{\mathrm{CNN}},p_{\mathrm{Stack}},p_{\mathrm{LGB}}]\in\mathbb{R}^3$，采用5折CV生成元特征并训练LogisticRegression(L2,C=1.0)与RandomForest(n_estimators=200,max_depth=10)两类元模型。

### 5.1.3 加权融合策略  
基于元模型输出概率$(p_{\mathrm{LR}},p_{\mathrm{RF}})$，应用加权融合：
\[
p_{\mathrm{final}}=\alpha\,p_{\mathrm{LR}}+(1-\alpha)\,p_{\mathrm{RF}},\quad \alpha\in[0,1].
\]
通过网格搜索在$\{0.1,0.2,\dots,0.9\}$区间确定最优$\alpha=0.6$，并以阈值0.5裁定最终标签。

### 5.1.4 推理流程与部署  
在Inference阶段，按上述并行→元模型→加权决策流程执行，平均单样本延迟<10ms，适合规模化部署。

## 5.2 Stacking集成方案细节

### 5.2.1 OOF预测生成策略  
为避免信息泄露，对训练集进行K=5折划分。每折基模型仅在4折训练，向第5折预测并收集概率，直至所有折完成。

### 5.2.2 元特征构造与融合形式  
合并三类子模型在测试集上的平均概率与训练集的OOF概率，构成$(N,3)$矩阵，作为元模型输入。

### 5.2.3 元模型训练与正则化  
LogisticRegression使用L2正则化防止过拟合；RandomForest采用Out‐Of‐Bag评价并调整树深度。

### 5.2.4 验证与对比  
通过ROC曲线(AUC)、Precision‐Recall曲线与混淆矩阵对比单一元模型与Stacking性能，证明Stacking在查全与查准之间取得更优平衡。

## 5.3 加权融合方案细节

### 5.3.1 权重参数优化  
通过在验证集上对$\alpha$进行网格搜索，以最大化F1分数；结果$\alpha=0.6$对应F1最高。

### 5.3.2 决策阈值与不确定样本处理  
默认阈值0.5，对于概率在$(0.45,0.55)$区间的不确定样本可触发二次人工审查流程。

### 5.3.3 实验结果及误差分析  
最终方案在测试集获得F1=0.943，误报率0.037，漏报率0.029。与单一LogisticRegression(F1=0.927)和单一RandomForest(F1=0.934)相比，F1分别提升1.6%与0.9%。

### 5.3.4 与其他融合方法对比  
与简单投票(Voting)和平均融合(Mean)相比，加权融合在权重最优时提高F1约0.8%。此外，使用Stacking+Weighted的组合优于纯Boosting或Bagging集成策略，适应性更强。

---

**参考文献**  
[1] LeCun, Y., et al. “Backpropagation Applied to Handwritten Zip Code Recognition.” Neural Computation, 1(4):541–551, 1989.  
[2] Breiman, L. “Random Forests.” Machine Learning, 45(1):5–32, 2001.  
[3] Ke, G., et al. “LightGBM: A Highly Efficient Gradient Boosting Decision Tree.” NIPS 2017.