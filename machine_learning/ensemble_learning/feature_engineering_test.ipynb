{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import copy\n",
    "import time\n",
    "import lief\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/jovyan/feature_engineering/feature_engineering_features.pkl\", 'rb') as f:\n",
    "    feature_engineering_features = pickle.load(f)\n",
    "with open(\"models/keys.pkl\", 'rb') as f:\n",
    "    keys = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/datacon/malware/XXX/black.txt\", 'r') as f:\n",
    "    black_list = f.read().strip().split()\n",
    "\n",
    "with open(\"/home/datacon/malware/XXX/white.txt\", 'r') as f:\n",
    "    white_list = f.read().strip().split()\n",
    "\n",
    "with open(\"models/hash_list.pkl\", 'rb') as f:\n",
    "    hash_list = pickle.load(f)\n",
    "\n",
    "train_features = []\n",
    "for ha in hash_list:\n",
    "    if ha in black_list:\n",
    "        train_features.append(1)\n",
    "    else:\n",
    "        train_features.append(0)\n",
    "\n",
    "train_features = np.array(train_features, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11647,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(feature_engineering_features, columns=keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[500]\ttraining's binary_logloss: 0.0622826\tvalid_1's binary_logloss: 0.0692178\n",
      "[1000]\ttraining's binary_logloss: 0.0380324\tvalid_1's binary_logloss: 0.054276\n",
      "[1500]\ttraining's binary_logloss: 0.026614\tvalid_1's binary_logloss: 0.0492136\n",
      "[2000]\ttraining's binary_logloss: 0.0193443\tvalid_1's binary_logloss: 0.046569\n",
      "[2500]\ttraining's binary_logloss: 0.0148735\tvalid_1's binary_logloss: 0.045438\n",
      "Early stopping, best iteration is:\n",
      "[2740]\ttraining's binary_logloss: 0.0132744\tvalid_1's binary_logloss: 0.0452006\n",
      "Finished loading model, total used 2740 iterations\n",
      "fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[500]\ttraining's binary_logloss: 0.0592194\tvalid_1's binary_logloss: 0.0770158\n",
      "[1000]\ttraining's binary_logloss: 0.0367177\tvalid_1's binary_logloss: 0.0628496\n",
      "[1500]\ttraining's binary_logloss: 0.0256375\tvalid_1's binary_logloss: 0.0581123\n",
      "[2000]\ttraining's binary_logloss: 0.0187458\tvalid_1's binary_logloss: 0.0554952\n",
      "[2500]\ttraining's binary_logloss: 0.0146185\tvalid_1's binary_logloss: 0.054573\n",
      "Early stopping, best iteration is:\n",
      "[2668]\ttraining's binary_logloss: 0.0135243\tvalid_1's binary_logloss: 0.0543697\n",
      "Finished loading model, total used 2668 iterations\n",
      "fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[500]\ttraining's binary_logloss: 0.0589963\tvalid_1's binary_logloss: 0.0808982\n",
      "[1000]\ttraining's binary_logloss: 0.034963\tvalid_1's binary_logloss: 0.0696653\n",
      "Early stopping, best iteration is:\n",
      "[1294]\ttraining's binary_logloss: 0.0276091\tvalid_1's binary_logloss: 0.0679925\n",
      "Finished loading model, total used 1294 iterations\n",
      "fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[500]\ttraining's binary_logloss: 0.0627042\tvalid_1's binary_logloss: 0.0657594\n",
      "[1000]\ttraining's binary_logloss: 0.038282\tvalid_1's binary_logloss: 0.0519841\n",
      "[1500]\ttraining's binary_logloss: 0.0273375\tvalid_1's binary_logloss: 0.0475178\n",
      "[2000]\ttraining's binary_logloss: 0.0202554\tvalid_1's binary_logloss: 0.0454211\n",
      "Early stopping, best iteration is:\n",
      "[2088]\ttraining's binary_logloss: 0.0193356\tvalid_1's binary_logloss: 0.0451811\n",
      "Finished loading model, total used 2088 iterations\n",
      "fold 5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[500]\ttraining's binary_logloss: 0.0620011\tvalid_1's binary_logloss: 0.0753361\n",
      "[1000]\ttraining's binary_logloss: 0.038365\tvalid_1's binary_logloss: 0.0619157\n",
      "[1500]\ttraining's binary_logloss: 0.0269653\tvalid_1's binary_logloss: 0.0578915\n",
      "Early stopping, best iteration is:\n",
      "[1689]\ttraining's binary_logloss: 0.0238503\tvalid_1's binary_logloss: 0.0570982\n",
      "Finished loading model, total used 1689 iterations\n"
     ]
    }
   ],
   "source": [
    "params = {'num_leaves': 20,\n",
    "          'min_data_in_leaf': 1,\n",
    "          'objective': 'binary', #定义的目标函数\n",
    "          'max_depth': 4,\n",
    "          'learning_rate': 0.01,\n",
    "          \"min_sum_hessian_in_leaf\": 4,\n",
    "          \"boosting\": \"gbdt\",\n",
    "          \"feature_fraction\": 0.9,  #提取的特征比率\n",
    "          \"bagging_freq\": 1,\n",
    "          \"bagging_fraction\": 0.9,\n",
    "          \"bagging_seed\": 11,\n",
    "          \"nthread\": 10,\n",
    "          'metric': {'binary_logloss'},  \n",
    "          \"random_state\": 6666,\n",
    "}\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "kf = StratifiedKFold(n_splits=n_splits, random_state=2200, shuffle=True)\n",
    "\n",
    "prob_oof = np.zeros((len(train_features), ))\n",
    "\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "lgb_models = []\n",
    "\n",
    "for fold_idx, (train_index, test_index) in enumerate(kf.split(train_df, train_features)):\n",
    "    print(\"fold {}\".format(fold_idx+1))\n",
    "    trn_data = lgb.Dataset(train_df.iloc[train_index], label=train_features[train_index])\n",
    "    val_data = lgb.Dataset(train_df.iloc[test_index], label=train_features[test_index])\n",
    "\n",
    "    lgb_model = lgb.train(params,\n",
    "                          trn_data,\n",
    "                          3000,\n",
    "                          valid_sets=[trn_data, val_data],\n",
    "                          early_stopping_rounds=50,\n",
    "                          verbose_eval=500)\n",
    "    prob_oof[test_index] = lgb_model.predict(train_df.iloc[test_index], num_iteration=lgb_model.best_iteration)\n",
    "\n",
    "    lgb_models.append(copy.deepcopy(lgb_model))\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = keys\n",
    "    fold_importance_df[\"importance\"] = lgb_model.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_idx + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>entr_X</td>\n",
       "      <td>1166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>entr_X</td>\n",
       "      <td>1089</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>size_R_weight</td>\n",
       "      <td>1032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>size_X_weight</td>\n",
       "      <td>1016</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>size_X_weight</td>\n",
       "      <td>996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>pe_mean</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mz_mean</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mz_mean</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>pe_mean</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mz_mean</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Feature  importance  fold\n",
       "33         entr_X        1166     1\n",
       "33         entr_X        1089     2\n",
       "34  size_R_weight        1032     1\n",
       "10  size_X_weight        1016     2\n",
       "10  size_X_weight         996     1\n",
       "..            ...         ...   ...\n",
       "26        pe_mean           0     1\n",
       "2         mz_mean           0     4\n",
       "2         mz_mean           0     2\n",
       "26        pe_mean           0     3\n",
       "2         mz_mean           0     3\n",
       "\n",
       "[280 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df.sort_values(by=\"importance\", ascending=False) # .to_csv(\"importance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3775"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([0 if i < 0.5 else 1 for i in prob_oof])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"oof/feature_engineerin_train.pkl\", \"wb\") as fp:\n",
    "#     pickle.dump(prob_oof.reshape((len(train_features), 1)), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/lgb_models.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(lgb_models, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yuri",
   "language": "python",
   "name": "yuri"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}